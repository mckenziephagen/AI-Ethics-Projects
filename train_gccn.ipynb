{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de795979-29ba-42c1-9308-c8bbcf074946",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code adapted from https://medium.com/stanford-cs224w/gnns-in-neuroscience-graph-convolutional-networks-for-fmri-analysis-8a2e933bd802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89435e3-52c9-44c4-883d-1c1a54868468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9559655-15a3-464a-b47a-7eb15067a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU, BatchNorm1d\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset, Data, DataLoader\n",
    "from torch_geometric.nn import EdgeConv, GCNConv, GraphConv\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.convert_matrix import from_numpy_array\n",
    "from torch_geometric.utils import from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1b4951-83bb-4eb3-b4b5-6cf93665fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_list = np.loadtxt('corr_matrix.csv', delimiter=',',  skiprows=1) \n",
    "pcorr_matrix_list = np.loadtxt('pcorr_matrix.csv', delimiter=',',  skiprows=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8676b139-e3f5-4a58-b29e-673630277de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = 'labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce46cfe-069a-4e69-a5d6-e6dfe2ff2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DevDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, neighbors=10):\n",
    "        self.neighbors = neighbors\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\" Converts raw data into GNN-readable format by constructing\n",
    "        graphs out of connectivity matrices.\n",
    "\n",
    "        \"\"\"\n",
    "        # Paths of connectivity matrices\n",
    "        \n",
    "        graphs = []\n",
    "        labels = torch.from_numpy(np.loadtxt(labels_file, delimiter=',',  skiprows=1))\n",
    "        for i in range(pcorr_matrix_list.shape[0]): \n",
    "            pcorr_matrix_np = pcorr_matrix_list[i].reshape(50,50)\n",
    "            index = np.abs(pcorr_matrix_np).argsort(axis=1)\n",
    "            n_rois = pcorr_matrix_np.shape[0]\n",
    "\n",
    "            for j in range(n_rois):\n",
    "                for k in range(n_rois - self.neighbors):\n",
    "                    pcorr_matrix_np[j, index[j, k]] = 0\n",
    "                for k in range(n_rois - self.neighbors, n_rois):\n",
    "                    pcorr_matrix_np[j, index[j, k]] = 1\n",
    "\n",
    "            pcorr_matrix_nx = from_numpy_array(pcorr_matrix_np)\n",
    "            pcorr_matrix_data = from_networkx(pcorr_matrix_nx)\n",
    "            \n",
    "            # Correlation matrix which will serve as our features\n",
    "            corr_matrix_np = corr_matrix_list[i]\n",
    "            \n",
    "            pcorr_matrix_data.x = torch.tensor(corr_matrix_np).float()\n",
    "            pcorr_matrix_data.y = labels[i].type(torch.LongTensor)\n",
    "            \n",
    "            # Add to running list of all dataset items\n",
    "            graphs.append(pcorr_matrix_data)\n",
    "            \n",
    "        data, slices = self.collate(graphs)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6885f614-e8fe-4924-969e-07f35d652773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize MLPs used by EdgeConv layers\n",
    "        self.mlp1 = Sequential(Linear(2 * dataset.num_node_features, hidden_channels), ReLU())\n",
    "        self.mlp2 = Sequential(torch.nn.Linear(2 * hidden_channels, hidden_channels), ReLU())\n",
    "        self.mlp3 = Sequential(torch.nn.Linear(2 * hidden_channels, hidden_channels), ReLU())\n",
    "\n",
    "        # Initialize EdgeConv layers\n",
    "        self.conv1 = EdgeConv(self.mlp1, aggr='max')\n",
    "        self.conv2 = EdgeConv(self.mlp2, aggr='max')\n",
    "        self.conv3 = EdgeConv(self.mlp3, aggr='max')\n",
    "\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "\n",
    "        self.linear = torch.nn.Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\" Performs a forward pass on our simplified cGCN.\n",
    "\n",
    "        Parameters:\n",
    "        data (Data): Graph being passed into network.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor (N x 2): Probability distribution over class labels.\n",
    "        \"\"\"\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.linear(x)        \n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2947321c-50d4-417f-b12b-22dc570d12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, device, data_loader, optimizer):\n",
    "    \"\"\" Performs an epoch of model training.\n",
    "\n",
    "    Parameters:\n",
    "    model (nn.Module): Model to be trained.\n",
    "    loss_fn (nn.Module): Loss function for training.\n",
    "    device (torch.Device): Device used for training.\n",
    "    data_loader (torch.utils.data.DataLoader): Data loader containing all batches.\n",
    "    optimizer (torch.optim.Optimizer): Optimizer used to update model.\n",
    "\n",
    "    Returns:\n",
    "    float: Total loss for epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        print(batch.x)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "\n",
    "        loss = loss_fn(out, batch.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def eval(model, device, loader):\n",
    "    \"\"\" Calculate accuracy for all examples in a DataLoader.\n",
    "\n",
    "    Parameters:\n",
    "    model (nn.Module): Model to be evaluated.\n",
    "    device (torch.Device): Device used for training.\n",
    "    loader (torch.utils.data.DataLoader): DataLoader containing examples to test.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(model(batch), 1)\n",
    "\n",
    "        y = batch.y\n",
    "        cor += (pred == y).sum()\n",
    "        tot += pred.shape[0]\n",
    "\n",
    "    return cor / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "945ee1d2-8374-439d-9cff-bd13ecbf11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = DevDataset('pyg')\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "# Train/test split (80-20)\n",
    "train_share = int(len(dataset) * 0.8)\n",
    "\n",
    "train_dataset = dataset[:train_share]\n",
    "test_dataset = dataset[train_share:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d471692b-7f4a-4d79-975f-8313a34039c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0.0000, -13.3640,  16.1720,  ...,   1.3971,   1.0253,   0.0000])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     train_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(model, device, train_loader)\n\u001b[1;32m     15\u001b[0m     test_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(model, device, test_loader)\n",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, device, data_loader, optimizer)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, batch\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/home/groups/jyeatman/MPH_code/miniconda3/envs/pytorch-e/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mGraphNetwork.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Performs a forward pass on our simplified cGCN.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03mtorch.Tensor (N x 2): Probability distribution over class labels.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m x, edge_index, batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mbatch\n\u001b[0;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m/home/groups/jyeatman/MPH_code/miniconda3/envs/pytorch-e/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/groups/jyeatman/MPH_code/miniconda3/envs/pytorch-e/lib/python3.10/site-packages/torch_geometric/nn/conv/edge_conv.py:60\u001b[0m, in \u001b[0;36mEdgeConv.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     58\u001b[0m     x: PairTensor \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor)\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/groups/jyeatman/MPH_code/miniconda3/envs/pytorch-e/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:459\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    457\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 459\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/home/groups/jyeatman/MPH_code/miniconda3/envs/pytorch-e/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:331\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dim], Tensor):\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[dim]\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n",
      "File \u001b[0;32m/home/groups/jyeatman/MPH_code/miniconda3/envs/pytorch-e/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:243\u001b[0m, in \u001b[0;36mMessagePassing._set_size\u001b[0;34m(self, size, dim, src)\u001b[0m\n\u001b[1;32m    241\u001b[0m the_size \u001b[38;5;241m=\u001b[39m size[dim]\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m the_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     size[dim] \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m the_size \u001b[38;5;241m!=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m         (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncountered tensor with size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but expected size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthe_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GraphNetwork(32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "losses = []\n",
    "\n",
    "for epoch in range(0, 30):\n",
    "    loss = train(model, loss_fn, device, train_loader, optimizer)\n",
    "    train_result = eval(model, device, train_loader)\n",
    "    test_result = eval(model, device, test_loader)\n",
    "    \n",
    "    losses.append(loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_result:.2f}%, '\n",
    "          f'Test: {100 * test_result:.2f}%')\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68998060-1355-4b92-baf3-56aed27e1328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-e]",
   "language": "python",
   "name": "conda-env-pytorch-e-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
